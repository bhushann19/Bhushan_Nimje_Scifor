{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2660c5d2",
   "metadata": {},
   "source": [
    "### 1. Training Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50907e4",
   "metadata": {},
   "source": [
    "Purpose: The training dataset is used to fit the machine learning model. The model learns the patterns, relationships, and structures within this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd528aa6",
   "metadata": {},
   "source": [
    "#### Characteristics:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7c99f9",
   "metadata": {},
   "source": [
    "1. The largest portion of the data is typically assigned to the training set to ensure the model has enough information to learn from.\n",
    "2. During training, the model adjusts its parameters (e.g., weights in a neural network) to minimize the error on this data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ae759e",
   "metadata": {},
   "source": [
    "#### Usage "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9069a65f",
   "metadata": {},
   "source": [
    "1. Used for training the model and updating the model parameters.\n",
    "2. Can be used to estimate the model's performance during the training process through metrics like loss or accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524353fa",
   "metadata": {},
   "source": [
    "### 2. Validation Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89aeaa7",
   "metadata": {},
   "source": [
    "Purpose: The validation dataset is used to tune the model's hyperparameters and to prevent overfitting. It helps in evaluating the model’s performance during the training process without affecting the training of the model itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc031d3a",
   "metadata": {},
   "source": [
    "#### Characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a69e79f",
   "metadata": {},
   "source": [
    "1. The validation set is separate from the training set and is used to validate the model during the training process.\n",
    "2. It's used to select the best model among different versions trained with different hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0136398",
   "metadata": {},
   "source": [
    "#### Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068df2bc",
   "metadata": {},
   "source": [
    "1. Used for model selection and hyperparameter tuning (e.g., learning rate, number of layers in a neural network, regularization strength).\n",
    "2. Helps in early stopping to prevent overfitting. If the performance on the validation set starts to degrade while the performance on the training set improves, training can be halted.\n",
    "3. Common techniques include k-fold cross-validation, where the training data is split into k subsets and the model is trained and validated k times, each time using a different subset as the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef963d5",
   "metadata": {},
   "source": [
    "### 3. Test Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9030fa79",
   "metadata": {},
   "source": [
    "Purpose: The test dataset is used to provide an unbiased evaluation of a final model fit on the training dataset. It helps in assessing how well the model generalizes to new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ffaaee",
   "metadata": {},
   "source": [
    "#### Characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f978dfd",
   "metadata": {},
   "source": [
    "1. The test set is strictly used after the model has been trained and validated.\n",
    "2. It should never be used during the training or validation phases to ensure a fair assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3e005f",
   "metadata": {},
   "source": [
    "#### Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584c7c71",
   "metadata": {},
   "source": [
    "1. Used for the final evaluation of the model’s performance.\n",
    "2. Provides an estimate of how well the model is likely to perform on real-world data.\n",
    "3. Performance metrics (e.g., accuracy, precision, recall, F1-score, mean squared error) computed on the test set are reported as the model's generalization ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b8ec92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (600, 10)\n",
      "Validation set size: (200, 10)\n",
      "Test set size: (200, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate some sample data\n",
    "np.random.seed(0)\n",
    "X = np.random.rand(1000, 10)  # 1000 samples, 10 features\n",
    "y = np.random.randint(0, 2, 1000)  # Binary target\n",
    "\n",
    "# Split data into training+validation and test sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split training+validation into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Validation set size:\", X_val.shape)\n",
    "print(\"Test set size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaa96b4",
   "metadata": {},
   "source": [
    "### Code Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ed714b",
   "metadata": {},
   "source": [
    "1. Data Generation: We generate a dataset with 1000 samples and 10 features, with a binary target.\n",
    "2. Initial Split: We split the data into training+validation and test sets using an 80-20 split. This ensures that 20% of the data is reserved for testing.\n",
    "3. Second Split: We further split the training+validation set into training and validation sets using a 75-25 split. This ensures that 20% of the total data (0.25 x 0.8) is used for validation.\n",
    "4. Print Sizes: We print the sizes of the resulting datasets to confirm the splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c150cc28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
