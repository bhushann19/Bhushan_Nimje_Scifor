{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22fe9d9e",
   "metadata": {},
   "source": [
    "Cross-validation is a resampling technique used in machine learning to assess the performance of a model and to mitigate issues such as overfitting and selection bias. It involves partitioning the dataset into complementary subsets, performing multiple iterations of training and validation, and averaging the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f415f36",
   "metadata": {},
   "source": [
    "### Types of Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1949d604",
   "metadata": {},
   "source": [
    "1. K-Fold Cross-Validation\n",
    "2. Leave-One-Out Cross-Validation (LOOCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951bdab0",
   "metadata": {},
   "source": [
    "### 1. K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0999f8",
   "metadata": {},
   "source": [
    "In k-fold cross-validation, the dataset is divided into k equal-sized folds. The model is trained k times, each time using k-1 folds for training and the remaining fold for validation. The performance metrics are then averaged over the k iterations to obtain the final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29989591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [1.         1.         0.93333333 0.96666667 0.96666667]\n",
      "Average Accuracy: 0.9733333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhushannimje/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the iris dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Initialize a logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Define the number of folds\n",
    "k = 5\n",
    "\n",
    "# Initialize a k-fold cross-validation object\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "scores = cross_val_score(model, X, y, cv=kf)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-Validation Scores:\", scores)\n",
    "print(\"Average Accuracy:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d25da78",
   "metadata": {},
   "source": [
    "#### Code Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25e4faa",
   "metadata": {},
   "source": [
    "1. Load Data: We load the iris dataset, which contains features (X) and target labels (y).\n",
    "2. Initialize Model: We initialize a logistic regression model.\n",
    "3. Define K-Fold Cross-Validation: We define the number of folds (k) and initialize a k-fold cross-validation object.\n",
    "4. Perform Cross-Validation: We use cross_val_score to perform k-fold cross-validation on the model using the specified number of folds.\n",
    "5. Print Results: We print the cross-validation scores and calculate the average accuracy across all folds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed7c0ce",
   "metadata": {},
   "source": [
    "### 2. Leave-One-Out Cross-Validation (LOOCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494ca475",
   "metadata": {},
   "source": [
    "In leave-one-out cross-validation, each data point is used as the validation set exactly once, with the remaining data points used for training. This is repeated for each data point in the dataset. It is computationally expensive for large datasets but provides an unbiased estimate of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9ff6482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Mean Squared Error: 3.5991778800708664e-30\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Generate some sample data\n",
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "y = np.array([3, 7, 11, 15])\n",
    "\n",
    "# Initialize Leave-One-Out Cross-Validation\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Initialize an empty list to store the mean squared errors\n",
    "mse_scores = []\n",
    "\n",
    "# Iterate over the Leave-One-Out splits\n",
    "for train_index, val_index in loo.split(X):\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    # Initialize and train the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate the mean squared error\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    \n",
    "    # Store the mean squared error\n",
    "    mse_scores.append(mse)\n",
    "\n",
    "# Compute the average mean squared error\n",
    "avg_mse = np.mean(mse_scores)\n",
    "print(\"Average Mean Squared Error:\", avg_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c80645",
   "metadata": {},
   "source": [
    "#### Code Explanation: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc879148",
   "metadata": {},
   "source": [
    "1. Generate Sample Data: We create a sample dataset with 4 data points and 2 features.\n",
    "2. Initialize Leave-One-Out Cross-Validation: We initialize the LeaveOneOut object, which generates the indices for Leave-One-Out splits.\n",
    "3. Iterate over Splits: We loop over each Leave-One-Out split, where each iteration provides the indices for the training and validation sets.\n",
    "4. Train and Validate Model: For each split, we train a Linear Regression model on the training set and validate it on the single data point left out.\n",
    "5. Calculate Mean Squared Error: We calculate the mean squared error between the actual and predicted values for the validation set.\n",
    "6. Store Mean Squared Error: We store the mean squared error for each iteration.\n",
    "7. Compute Average Mean Squared Error: Finally, we compute the average mean squared error over all iterations, providing an overall evaluation of the model's performance using LOOCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370c06ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
